# C++多线程与同步

- 不同的操作系统，对于类似的功能，会提供不同的API
  - 比如Windows和Linux有各自访问文件、访问控制台的API函数
  - 同一个App，面向不同的系统，需要调用不同的API，不便
- 编程语言往往也会针对这些功能提供自己的标准库
  - 比如C++针对文件提供了fstream类，针对控制台提供了cin、cout类等
  - 这些类本质上是对操作系统API的封装，但作为C++的标准，让程序员不必面对系统的差异
- 针对线程管理、同步问题，C++从11版开始提供自己的标准库
  - 参考：https://www.bilibili.com/video/BV1d841117SH

## 线程

```
#include <thread>
```

创建线程
```
std::thread t1(入口函数, 入口函数参数);
```
例
```
void f(int m, int n) {
	...
}
class A {
	...
public:
	void g() {
		...
	}
};
int main() {
	int a = 1;
	std::thread t1(f, a, 3);
	A a;
	std::thread t2(&A::g, &a);
	...
}
```

一般情况下，主线程有义务**阻塞等待**子线程结束
```
if(t1.joinable())
	t1.join();
```

若子线程与主线程脱离，则主线程不必等待子线程结束
```
t1.detatch();
```

其它
- ``std::this_thread::get_id()``
- ``std::this_thread::sleep_for()``

## 线程传参

以下程序有问题，创建t1的代码并不知道``a``参数要以引用方式传递
```
void fun(int &x) {
	...
}
int main() {
	int a = 1;
	std::thread t1(fun, a);
	...
}
```
解决办法
```
...
std::thread t1(fun, std::ref(a));
...
```

## 互斥锁

```
#include <mutex>
```
```
...
int a = 0;
std::mutex mtx;
void fun() {
	for (int i = 0; i < 10000; i++) {
		mtx.lock();
		a++;
		mtx.unlock();
	}
}
int main() {
	std::thread t1(fun);
	std::thread t2(fun);
	t1.join();
	t2.join();
	std::cout << a << std::endl;
	return 0;
}
```

### ``std::timed_mutex``

实现有时限的阻塞

- ``std::timed_mutex::try_lock_for(xxx)``

尝试上锁，若失败则最多阻塞等待**指定的时长**，到点后还不成功则返回``false``，例

```
std::timed_mutex::try_lock_for(std::chrono::milliseconds(100))
```
尝试上锁，若失败则最多阻塞等待100ms

- ``std::timed_mutex::try_lock_until(xxx)``，尝试上锁，若失败则最多阻塞等待**至指定的时刻**，到点后还不成功则返回``false``，例
 
```
std::timed_mutex::try_lock_until(std::chrono::steady_clock::now() + std::chrono::second(10))
```
尝试上锁，若失败则最多阻塞等待10s

## ``lock_guard``与``unique_lock``

对互斥锁的对象化封装，``lock_guard``比较简单，``unique_lock``更复杂、强大一些

### ``lock_guard``

```
std::mutex mtx;
std::lock_guard<std::mutex> lg(mtx);
```
以上代码创建``lock_guard``对象``lg``，其构造函数将对``mtx``执行上锁，析构函数对``mtx``解锁，方便局部范围上锁，例
```
...
std::mutex mtx;
int a = 0;
void f() {
    for (int i = 0; i < 100; i++) {
        std::lock_guard<std::mutex> lg(mtx);
        a++;
    }
}
...
```
以上代码等效于
```
...
std::mutex mtx;
int a = 0;
void f() {
    for (int i = 0; i < 100; i++) {
        mtx.lock();
        a++;
        mtx.unlock();
    }
}
...
```

### ``unique_lock``

拥有``lock_guard``的全部功能，并提供更多功能

- ``std::unique_lock<std::mutex> ul(mtx, std::defer_lock)``，创建``ul``对象，但构造函数中不自动上锁，以便后续手动上锁
- ``ul.try_lock()``，尝试上锁，失败则立刻返回``false``，不阻塞，成功则返回``true``
- 可与``std::timed_mutex``搭配，实现有时限的阻塞
  - ``ul.try_lock_for(std::chrono::milliseconds(100))``，尝试上锁，若失败则最多阻塞等待100ms，到点后还不成功则返回``false``
  - ``ul.try_lock_until(std::chrono::steady_clock::now() + std::chrono::seconds(10))``，尝试上锁，若失败则最多阻塞等待10s，到点后还不成功则返回``false``

### 构造函数的第二个参数

- ``std::defer_lock``，创建对象，但不上锁
- ``std::adopt_lock``，创建对象时锁已关闭，因此不上锁，程序需确保此时锁处于关闭状态，否则出错
- ``std::try_to_lock``，创建对象，尝试上锁，但如果失败，不阻塞等待，继续执行

## 共享锁（读写锁）

```
#include <shared_mutex>
```

允许多个线程读（使用``std::shared_lock``共享上锁），只允许一个线程写（使用``std::unique_lock``独占上锁）
```
#include <iostream>
#include <shared_mutex>
#include <thread>

std::shared_mutex rw_mutex;
int shared_data = 0;

void reader_function(int id) {
    std::shared_lock<std::shared_mutex> lock(rw_mutex);
    std::cout << "Reader " << id << " sees value " << shared_data << std::endl;
}

void writer_function(int id) {
    std::unique_lock<std::shared_mutex> lock(rw_mutex);
    ++shared_data;
    std::cout << "Writer " << id << " updated value to " << shared_data << std::endl;
}

int main() {
    std::thread readers[5], writer;

    // 创建读线程
    for (int i = 0; i < 5; ++i)
        readers[i] = std::thread(reader_function, i);

    // 创建写线程
    writer = std::thread(writer_function, 0);

    for (int i = 0; i < 5; ++i)
        readers[i].join();
    writer.join();

    return 0;
}
```

## ``std::call_once``

确保指定的函数只被执行一次，例
```
...
std::once_flag flag1;

void simple_do_once() {
    std::call_once(flag1, [](){ std::cout << "Simple example: called once\n"; });
}

int main() {
    std::thread st1(simple_do_once);
    std::thread st2(simple_do_once);
    st1.join();
    st2.join();
    return 0;
}
...
```

常见用途：单例模式
- 传统写法，如果多个线程同时执行``getInstance()``，可能造成``new``操作执行多次
- 例

```
class Singleton {
private:
    static std::once_flag oc;
    static Singleton* m_instance;
    Singleton() {}

public:
    static Singleton* getInstance() {
        std::call_once(oc, [&]() { m_instance = new Singleton(); });
        return m_instance;
    }
};

Singleton* Singleton::m_instance = nullptr;
std::once_flag Singleton::oc;
```

## ``std::condition_variable``

```
#include <condition_variable>
```

相关操作
- ``std::condition_variable::wait()``，阻塞等待某个条件成立
- ``std::condition_variable::wait_for()``，阻塞等待某个条件成立，限定时长
- ``std::condition_variable::wait_until()``，阻塞等待某个条件成立，限定时间点
- ``std::condition_variable::notify_one()``，唤醒某个等待条件成立的线程
- ``std::condition_variable::notify_all()``，唤醒所有等待条件成立的线程

``wait()``使用方法：与``std::unique_lock``配合，与条件判别表达式配合
```
std::condition_variable cv;
std::mutex mtx;
bool condition;
```
写法一：
```
std::unique_lock<std::mutex> lock(mtx);
while(!condition)
    cv.wait(lock);
```
写法二（与写法一等价）：
```
std::unique_lock<std::mutex> lock(mtx);
cv.wait(lock, [](){ return condition; });
```

### 例：生产者-消费者

```
#include <iostream>
#include <thread>
#include <mutex>
#include <condition_variable>

int buffer[8];
int in = 0, out = 0, count = 0;
std::condition_variable notFull, notEmpty;
std::mutex mtx;

void produce() {
    for (int i = 0; i < 1000; i++) {
        std::unique_lock<std::mutex> lock(mtx);
        notFull.wait(lock, []() { return (count < 8); });
        count++;
        buffer[in] = i;
        in = (in + 1) % 8;
        lock.unlock();
        notEmpty.notify_one();
    }
}

void consume() {
    for (int i = 0; i < 1000; i++) {
        std::unique_lock<std::mutex> lock(mtx);
        notEmpty.wait(lock, []() { return (count > 0); });
        count--;
        int j = buffer[out];
        out = (out + 1) % 8;
        lock.unlock();
        notFull.notify_one();
    }
}

int main() {
    std::thread t1(produce);
    std::thread t2(produce);
    std::thread t3(produce);
    std::thread t4(consume);
    std::thread t5(consume);
    std::thread t6(consume);
    t1.join();
    t2.join();
    t3.join();
    t4.join();
    t5.join();
    t6.join();
    std::cout << "Over" << std::endl;
    return 0;
}
```

## ``std::counting_semaphore``和``std::binary_semaphore``

C++20才引入
```
#include <semaphore>
```

关键用法
```
std::counting_semaphore<10> sem(1); // 初始值为1，最大值为10
...
sem.acquire(); // 获取信号量
... // 执行关键代码
sem.release(); // 释放信号量
```

### 例：生产者-消费者

```
#include <iostream>
#include <semaphore>
#include <thread>

std::binary_semaphore b_mutex(1); // 用于互斥的二进制信号量
std::counting_semaphore<5> b_full(0); // 表示缓冲区已满的位置数
std::counting_semaphore<5> b_empty(5); // 表示缓冲区空闲的位置数

void Producer() {
    while (true) {
        b_empty.acquire(); // 等待空闲位置
        b_mutex.acquire(); // 获取互斥锁
        std::cout << "Producer\n";
        b_mutex.release(); // 释放互斥锁
        b_full.release(); // 通知消费者有产品可消费
        std::this_thread::sleep_for(std::chrono::seconds(2)); // 模拟生产过程
    }
}

void Consumer() {
    while (true) {
        b_full.acquire(); // 等待产品
        b_mutex.acquire(); // 获取互斥锁
        std::cout << "Consumer\n";
        b_mutex.release(); // 释放互斥锁
        b_empty.release(); // 通知生产者有空闲位置
        std::this_thread::sleep_for(std::chrono::seconds(2)); // 模拟消费过程
    }
}

int main() {
    std::thread t0(Producer);
    std::thread t1(Producer);
    std::thread t2(Consumer);
    std::thread t3(Consumer);
    t0.join();
    t1.join();
    t2.join();
    t3.join();
    return 0;
}
```

## 异步

- ``std::async``提供最高层次的封装，适合做简单的事情，例如异步执行一个任务
  - 但要注意``std::future``析构阻塞的问题
- ``std::packaged_task``提供中等层次的封装，可以选择是否配合``std::thread``进行异步处理，没有析构阻塞的问题
- ``std::promise``是三者中最底层的工具，可以用来同步不同线程之间的消息

### ``async``与``future``

```
#include <future>
```

实现异步的函数调用，例
```
...
int fun() {
    ...
}
int main() {
    std::future<int> future_result = std::async(std::launch::async, fun);
    std::cout << future_result.get() << std::endl;
    return 0;
}
```
- ``std::async``实现了异步的函数调用，函数的执行结果将保存在``future_result``中
- 通过``future_result.get()``可获得结果，若此时``fun()``尚未执行完，则会阻塞主线程等待
- 不一定启动另一个线程，``std::launch::async``强制要求启动子线程

**注意**：如果子线程异步任务尚未执行完，主线程的``future``对象尚未拿到结果，却已经执行到末尾即将析构，则``future``对象析构函数会将主线程阻塞，例

```
auto sleep = [](int s) { std::this_thread::sleep_for(std::chrono::seconds(s)); };
{
    std::async( std::launch::async, sleep, 5 ); // 临时对象被析构，主线程阻塞5s
    std::async( std::launch::async, sleep, 5 ); // 临时对象被析构，主线程阻塞5s
}
```
以上程序``std::async``返回的``future``为临时对象，立即析构，但又尚未拿到异步任务的结果，因而阻塞主线程，因此上述程序的两个异步任务是逐个启动的，整体上需要执行10s

### ``packaged_task``

另一种实现异步函数调用的方法，例
```
...
int fun() {
    ...
}
int main() {
    std::packaged_task<int()> task(fun);
    std::future<int> future_result = task.get_future();
    std::thread t1(std::move(task));
    t1.join();
    std::cout << future_result.get() << std::endl;
    return 0;
}
```
- 定义``task``的时候只做了封装，未启动``fun()``的执行
- 需手动创建线程，以启动执行，所以控制更灵活

### ``promise``

``std::promise``和``std::future``可配对使用，方便的在线程间做数据传递
- 创建``std::promise``对象时，会自动关联一个``std::future``对象
- ``std::promise``提供``set_value()``方法，用于设置数据的值
- ``std::future``的``get()``方法用于获取数据的值
- 本质上是对线程间做数据同步的封装，便于程序书写，例

```
...
void asyncTask(std::promise<int>& promise) {
    // 执行异步任务
    std::this_thread::sleep_for(std::chrono::seconds(1));
    promise.set_value(42); // 设置结果
}

int main() {
    std::promise<int> prom;
    std::future<int> fut = prom.get_future();

    std::thread t(asyncTask, std::ref(prom));
    t.detach();

    // 主线程等待异步任务的结果
    int result = fut.get();
    std::cout << "Result: " << result << std::endl;

    return 0;
}
```

## ``std::atomic``

实现变量的原子性操作，例

```
...
std::atomic<int> shared_data = 0;
void f() {
    for (int i = 0; i < 100; i++) {
        shared_data++;  // 或 shared_data.fetch_add(1)
    }
}
int main() {
    shared_data = 10000;    // 或 shared_data.store(10000)
    std::thread t1(f);
    std::thread t1(f);
    t1.join();
    t2.join();
    std::cout << shared_data << std::endl;  // 或 shared_data.load()
    return 0;
}
```

### 基于``std::atomic``的自旋锁

```
#include <iostream>
#include <atomic>
#include <thread>

class SpinLock {
private:
    std::atomic_flag flag = ATOMIC_FLAG_INIT;

public:
    void lock() {
        while (flag.test_and_set(std::memory_order_acquire)) ;
    }

    void unlock() {
        flag.clear(std::memory_order_release);
    }
};

int num = 0;
SpinLock spinLock;

void increment() {
    for (int i = 0; i < 1000; ++i) {
        spinLock.lock();
        ++num;
        if(num % 100 == 0)
            std::cout << std::this_thread::get_id() << "\tnum = " << num << std::endl;
        spinLock.unlock();
    }
}

int main() {
    std::thread t1(increment);
    std::thread t2(increment);
    t1.join();
    t2.join();
    return 0;
}
```

# pthreads库

POSIX线程库，提供一整套线程管理和同步的API

```
#include <pthread.h>
```

## 基础操作

- ``pthread_t``
- ``pthread_create()``
- ``void *thread_func(void *arg_p)``
- ``pthread_join()``
- ``pthread_detach()``
- ``pthread_exit()``

```
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#define NUM_THREADS 5
void *PrintHello(void *threadid) {
    long tid;
    tid = (long) threadid;
    printf("Hello World! It's me, thread #%ld!\n", tid);
    pthread_exit(NULL);
}
int main(int argc, char *argv[]) {
    pthread_t threads[NUM_THREADS];
    int rc;
    long t;
    for (t = 0; t < NUM_THREADS; t++) {
        printf("In main: creating thread %ld\n", t);
        rc = pthread_create(&threads[t], NULL, PrintHello, (void *) t);
        if (rc) {
            printf("ERROR; return code from pthread_create() is %d\n", rc);
            exit(-1);
        }
    }
    for (t = 0; t < NUM_THREADS; t++)
        pthread_join(threads[t], NULL);
    pthread_exit(NULL);
}
```

## 互斥锁

- ``pthread_mutex_t``
- ``pthread_mutex_init()``
- ``pthread_mutex_destroy()``
- ``pthread_mutex_lock()``
- ``pthread_mutex_unlock()``

## 信号量

- ``sem_t``
- ``sem_init()``
- ``sem_destroy()``
- ``sem_wait()``
- ``sem_post()``

## 条件变量

- ``pthread_cond_t``
- ``pthread_cond_init()``
- ``pthread_cond_destroy()``
- ``pthread_cond_wait()``
  - 要结合互斥锁``pthread_mutex_t``使用
  - 条件变量导致阻塞时，会把互斥锁解锁
  - 条件变量满足而唤醒时，会重新申请互斥锁
- ``pthread_cond_signal()``
- ``pthread_cond_broadcast()``

## 原子变量

- ``atomic_t``
- ``atomic_read()``
- ``atomic_set()``
- ``atomic_add()``
- ``atomic_sub()``
- ``atomic_sub_and_test()``
- ``atomic_inc()``
- ``atomic_dec()``
- ``atomic_dec_and_test()``
- ``atomic_inc_and_test()``

## 自旋锁

- ``pthread_spinlock_t``
- ``pthread_spin_init()``
- ``pthread_spin_destroy()``
- ``pthread_spin_lock()``
- ``pthread_spin_unlock()``

## 读写锁

- ``pthread_rwlock_t``
- ``pthread_rwlock_init()``
- ``pthread_rwlock_destroy()``
- ``pthread_rwlock_rdlock()``
- ``pthread_rwlock_wrlock()``
- ``pthread_rwlock_unlock()``

# 关于内存屏障

由于编译优化和CPU乱序执行，造成数据的访问次序与程序书写顺序不一致，进而引发错乱，为此引入内存屏障。程序中标记内存屏障（Linux内核中多处可见mb()、rmb()、wmb()），则其前后程序必须依照程序原原本本执行，不得乱序。

**1）了解多核CPU的缓存一致性协议（MESI）**

参考：https://zhuanlan.zhihu.com/p/467782159

此文末尾谈及MESI优化、Store Buffers等，这部分可略过，搞清楚MESI即可

**2）理解内存屏障的理论知识**

参考：内存屏障（Memory Barrier）究竟是个什么鬼？

**3）学习C++的相关设计**

参考：C++11内存模型完全解读
